{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a987218f-62bb-4326-a4bd-e127aeb794f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.utils.data as pydata\n",
    "import torchmetrics as metrics\n",
    "\n",
    "from matplotlib.pylab import plt\n",
    "import sklearn.metrics as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91d766f6-6edd-4e1f-b95c-da4f9a0ecf8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from sklearn) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.23.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn->sklearn) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34505837-07d2-4ce9-b327-1a431136969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull in maverick data and full chromosome data\n",
    "maverick = pd.read_csv(f\"./T_vaginalis_G3.mavericks_for_ML.txt\", delimiter=\"\\t\")\n",
    "\n",
    "full_data = pd.read_csv(f\"./T_vaginalis_G3.genome.sequence.3column.txt\",delimiter=\"\\t\",names=[\"chromosome\",\"sequence\",\"length\"])\n",
    "full_data['chromosome'] = full_data['chromosome'].apply(lambda x : x.strip()[1:])\n",
    "\n",
    "# Filter out any chromosomes larger than 25million (temporary - data is too large)\n",
    "full_data = full_data[full_data['length'] >= 100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeb8934d-9d92-450f-b97b-5c2cafb57381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     chromosome   start     end  length  sequence ID note is_ideal  \\\n",
      "0         chr_I    3003   28269   25267          3.0  NaN      NaN   \n",
      "1         chr_I   34084   54353   20270          6.0  NaN      NaN   \n",
      "2         chr_I   61012   80953   19942         13.0  NaN      NaN   \n",
      "3         chr_I   85287   89073    3787         15.0  NaN      NaN   \n",
      "4         chr_I  101391  120415   19025         24.0  NaN      NaN   \n",
      "...         ...     ...     ...     ...          ...  ...      ...   \n",
      "4666     ctg_95       1    8480    8480      58067.0  NaN      NaN   \n",
      "4667     ctg_96       1    2790    2790      58068.0  NaN      NaN   \n",
      "4668     ctg_97    1913    3444    1532      58073.0  NaN      NaN   \n",
      "4669     ctg_99    2248   19838   17591      58079.0  NaN      NaN   \n",
      "4670     ctg_99   28626   43852   15227      58086.0  NaN      NaN   \n",
      "\n",
      "                                               sequence  \n",
      "0     GAATTCTCAAGTTAGTATGGCTAAGTCGTGTACTGAGGCACTGCGC...  \n",
      "1     AAAAAAAAAAAAAAAAAAAAAAAAAAAAAGGGTAGTGGGGCTTCCA...  \n",
      "2     ACTCATAGAAAAAGTTTAAAATAAACCGTTTTTCGTCAACGGTAAC...  \n",
      "3     TTTCTTGTCTATGGAGTCCATAATTTTTCCAACTGCTATGCAATAT...  \n",
      "4     GAACCTAGCCAATATGGAAACAAACCTACTTTTGTTTCTGCAGACT...  \n",
      "...                                                 ...  \n",
      "4666  CATTAGCACGCACCTGAATGGCAAAGCAACAATCCCTCATAAATCC...  \n",
      "4667  TGTACATTGAAACCTTACCTGCTAAAACAACTAAGGCGTCAATTGC...  \n",
      "4668  ATATGCTATTAAAATCATCTCAATAATGAGTCCATCCTTTCCGTCT...  \n",
      "4669  TCGAAATATTCTGTTATTTTTTCCTTCAGTAATGTTTAGTCTTCTT...  \n",
      "4670  AAGACTCATATACATACCATTGCAAATATTACAAACTTACAAGAAA...  \n",
      "\n",
      "[4671 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(maverick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9ffc152-9686-4200-843f-804457cbbc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    chromosome                                           sequence    length\n",
      "0       chr_IV  CATGCTAATGGAATGCGTCGTTACCCACCAGTAAAAGTATTTGTGA...  40211917\n",
      "1        chr_V  TAGTGAACGACTTCTCATCTGGAAAGAAACTGAAGTCTGAAGGTTT...  34657175\n",
      "2       chr_II  TTCCCAGAAACAGACTTAGAACAAATTCCCCTTTCTGTTACACTAT...  26081621\n",
      "3      chr_III  GCTACTGTTTTCGAAATAAAAAGAGTAAAAACAAATTTTTATAACT...  27737965\n",
      "4       chr_VI  TATTTTCCCTATATCATTCGTAAATTTTCTTTCTATATTCTTCAAG...  20331443\n",
      "5        chr_I  TTCAAAAATTTTCCCAAGAAGAAAAAATAATTAGGAAATTTAATAT...  27726287\n",
      "44      ctg_44  CCTGTTTTTTCACCCTCGTGACTTTGTCATAACTTCTTCGTAAATG...    109354\n",
      "86      ctg_87  TTTAACCTTTTATCTTCACCGAGTTCATCCGAAGATTGAACGTTAA...    357916\n",
      "87      ctg_88  TATTCGTGGAGTTATGGGCCATTAAAAAAAAGGAGGATTACGACCC...    114971\n",
      "113    ctg_114  ACATTGCTGGTAGTTCATATGCTTCAAAGTTTCTGACATGACCTTC...    312855\n",
      "127    ctg_128  TTCGAGGTATAAAGTTCTATACACCTTCTCCAAACTTCTATTCTAT...    223072\n",
      "155    ctg_156  GAGGTATAGTTCGAATACGAGTATAATATTTTTCCTGCCCAGTTGG...    233009\n",
      "163    ctg_164  TCCATCATAGTACGTTCCATAACACTATGGTAACAAAATCTATTAC...    156932\n",
      "169    ctg_170  AAAAGAACCACCAAAACCAACAGCTAATGAAATATTGTTCGAATAT...    170613\n",
      "171    ctg_172  GAAAACAGTGAAGAACAGCGAGTACGTAAAAAAACGTAGTCGCCAA...    305720\n",
      "185    ctg_186  GGTACTGAACGTCTATGATATAAGTCAATAGCAATGTCATTTAAAG...    236109\n"
     ]
    }
   ],
   "source": [
    "print(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0e99032-a23f-4c94-a2da-b8dc5d6c17f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f85f44c-d241-4ffe-90fc-32363e54d96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to turn a maverick sequence into a 2-d one hot encoding\n",
    "# with 4 rows, each representing one of four base pairs \n",
    "def one_hot_sequence(sequence, size):\n",
    "  a = np.zeros(size)\n",
    "  g = np.zeros(size)\n",
    "  c = np.zeros(size)\n",
    "  t = np.zeros(size)\n",
    "  for i, chr in enumerate(sequence):\n",
    "    if chr.upper() == 'A':\n",
    "      a[i] = 1\n",
    "    if chr.upper() == 'G':\n",
    "      g[i] = 1\n",
    "    if chr.upper() == 'C':\n",
    "      c[i] = 1\n",
    "    if chr.upper() == 'T':\n",
    "      t[i] = 1\n",
    "\n",
    "  return a, g, c, t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1266f5f4-f216-4bb8-9524-994ec8b09397",
   "metadata": {},
   "source": [
    "Below, loop over each maverick. Create a chunk of size 'size' (in this case 30000). Randomly choose a chunk from the chromosome that contains the current maverick in the loop. Create a one hot encoding representing that sequence and a mask representing the part of the sequence that is considered a maverick.\n",
    "\n",
    "EX:\n",
    "mav: [atatata....atatatat] (any size 30000 or less)\n",
    "\n",
    "chromosome: [catatata...atcgca] (a chromosome of exactly size 30000. In this case, index 1 of the chromosome is aligned with index 0 of the mav. The maverick is contained within the chromosome)\n",
    "\n",
    "mask: [01111111...00000] (1s represent indices associated with part of a maverick. 0s are not associated with mavericks)\n",
    "\n",
    "inputs: [\n",
    "    [1010101...10000]\n",
    "    [...]\n",
    "    [...]\n",
    "    [...]\n",
    "    [0101010...0100000]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca53f2f6-7c84-436d-97aa-30556d8e8225",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = []\n",
    "inputs = []\n",
    "\n",
    "for i, row in maverick.iterrows():\n",
    "  mav_start = row['start']\n",
    "  mav_end = row['end']\n",
    "\n",
    "  # get the chromosome associated with the current maverick in the iteration\n",
    "  chr_row = full_data[full_data['chromosome'] == row['chromosome']]\n",
    "  if chr_row.empty:\n",
    "    continue\n",
    "\n",
    "  # Get the sequence by chromosome name (i.e. chr_1)\n",
    "  chr_seq = chr_row.iloc[0]['sequence']\n",
    "\n",
    "  # Size (defined above) is the max length of an input. If the current maverick is less than the \n",
    "  # size limit, add padding.\n",
    "  if row['length'] < size:\n",
    "    padding_length = size - row['length']\n",
    "    padding_left = random.randrange(0, padding_length)\n",
    "    padding_right = padding_length - padding_left\n",
    "\n",
    "    start = mav_start - padding_left\n",
    "    end = mav_end + padding_right + 1\n",
    "\n",
    "    # Create a mask that represents the indices where the maverick is present in the sequence\n",
    "    mask = np.zeros(size)\n",
    "    mask[padding_left:row['length']] = 1\n",
    "\n",
    "    # test\n",
    "    if chr_seq[start+padding_left-1:end-(padding_right+1)] != row['sequence']:\n",
    "      print(f\"{i}th input is wrong.\")\n",
    "      print(f\"seq_start: {chr_seq[start+padding_left+1:start+padding_left+10]}, actual: {row['sequence'][0:10]}\")\n",
    "      print(f\"seq_end: {chr_seq[end-padding_right-10:end-(padding_right+2)]}, actual: {row['sequence'][-10:-1]}\")\n",
    "  else:\n",
    "    start = mav_start\n",
    "    end = mav_start + size\n",
    "\n",
    "    mask = np.ones(size)\n",
    "\n",
    "  inputs.append(one_hot_sequence(chr_seq[start:end], size))\n",
    "  \n",
    "  masks.append(mask)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7a80f64-1149-449a-988e-db0522a0232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the cells below so that the masks and targets\n",
    "# don't need to be created every time from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c728976-85ff-4374-8ac7-f1711ea99a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data = {'x': inputs, 'targets': masks}\n",
    "\n",
    "file = open(f\"./np_mav_data.pkl\", 'wb')\n",
    "\n",
    "pickle.dump(np_data, file)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6187accb-094d-40c8-aebb-dee84b51fa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor(np.asarray(np_data['targets'])).float()\n",
    "d = torch.tensor(np.asarray(np_data['x'])).float()\n",
    "d = d.reshape(d.shape[0], 1, d.shape[1], d.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d31f3ebc-11cc-49f4-89a7-fb53ea80d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 25\n",
    "\n",
    "dataset = pydata.TensorDataset(d, target)\n",
    "train_data, valid_data = pydata.random_split(dataset, [0.7, 0.3])\n",
    "train_dl = pydata.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dl = pydata.DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c7153e6-7bc8-432b-b62f-982928047eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAVDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.c1 = self.contract_block(1, 24, 3, (2, 1))\n",
    "        self.c2 = self.contract_block(24, 48, 3, 1)\n",
    "        self.c3 = self.contract_block(48, 96, 3, 1)\n",
    "\n",
    "        self.ex1 = self.expand_block(96, 48, 3, 1)\n",
    "        self.ex2 = self.expand_block(48*2, 24, 3, 1)\n",
    "        self.ex3 = self.expand_block(24*2, 1, 3, (2, 1), 2, (0, 1))\n",
    "\n",
    "        self.fl = torch.nn.MaxPool2d(kernel_size=(15, 1), stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.c1(x)\n",
    "        conv2 = self.c2(conv1)\n",
    "        conv3 = self.c3(conv2)\n",
    "\n",
    "        upconv1 = self.ex1(conv3)\n",
    "        upconv2 = self.ex2(torch.cat([upconv1, conv2], 1))\n",
    "        upconv3 = self.ex3(torch.cat([upconv2, conv1], 1))\n",
    "\n",
    "        out = self.fl(upconv3)\n",
    "        return out\n",
    "\n",
    "    def contract_block(self, in_channels, out_channels, kernel_size, padding):\n",
    "\n",
    "        contract = nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
    "            torch.nn.BatchNorm2d(out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
    "            torch.nn.BatchNorm2d(out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "                                 )\n",
    "\n",
    "        return contract\n",
    "\n",
    "    def expand_block(self, in_channels, out_channels, kernel_size, padding, output_stride=2, output_padding=1):\n",
    "\n",
    "        expand = nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=padding),\n",
    "            torch.nn.BatchNorm2d(out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding=padding),\n",
    "            torch.nn.BatchNorm2d(out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.ConvTranspose2d(out_channels, out_channels, kernel_size=3, stride=output_stride, padding=1, output_padding=output_padding) \n",
    "                                )\n",
    "        return expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bab02f9b-5245-4105-abb4-a028ee2d2059",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAVDetector(\n",
      "  (c1): Sequential(\n",
      "    (0): Conv2d(1, 24, kernel_size=(3, 3), stride=(1, 1), padding=(2, 1))\n",
      "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(2, 1))\n",
      "    (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (c2): Sequential(\n",
      "    (0): Conv2d(24, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (c3): Sequential(\n",
      "    (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (ex1): Sequential(\n",
      "    (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): ConvTranspose2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  )\n",
      "  (ex2): Sequential(\n",
      "    (0): Conv2d(96, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): ConvTranspose2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  )\n",
      "  (ex3): Sequential(\n",
      "    (0): Conv2d(48, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 1))\n",
      "    (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 1))\n",
      "    (4): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): ConvTranspose2d(1, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(0, 1))\n",
      "  )\n",
      "  (fl): MaxPool2d(kernel_size=(15, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# detector = torch.load('./ltr_detector.pt')\n",
    "# # detector.cuda()\n",
    "# print(detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9aea27e4-c61d-4bad-9297-8bc0959bb1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAVDetector(\n",
      "  (c1): Sequential(\n",
      "    (0): Conv2d(1, 24, kernel_size=(3, 3), stride=(1, 1), padding=(2, 1))\n",
      "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(2, 1))\n",
      "    (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (c2): Sequential(\n",
      "    (0): Conv2d(24, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (c3): Sequential(\n",
      "    (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (ex1): Sequential(\n",
      "    (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): ConvTranspose2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  )\n",
      "  (ex2): Sequential(\n",
      "    (0): Conv2d(96, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): ConvTranspose2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  )\n",
      "  (ex3): Sequential(\n",
      "    (0): Conv2d(48, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 1))\n",
      "    (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 1))\n",
      "    (4): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): ConvTranspose2d(1, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(0, 1))\n",
      "  )\n",
      "  (fl): MaxPool2d(kernel_size=(15, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "detector = MAVDetector()\n",
    "# detector.cuda()\n",
    "print(detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d34b7529-21bd-4b62-a9d9-e6b6617a9382",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_metric = metrics.JaccardIndex(task='binary')\n",
    "# iou_metric.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a149724-55eb-488e-98da-14b07fd2fa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save for output, stats, and figures\n",
    "vexample = {}\n",
    "texample = {}\n",
    "val_loss = []\n",
    "train_loss = []\n",
    "val_iou = []\n",
    "train_iou = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "900b2e0c-f8b2-4abf-a7b6-7e5a4916e4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, save_batch=False):\n",
    "    epoch_loss = 0\n",
    "    epoch_iou = 0\n",
    "    epoch_sum = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for (x, y) in iterator:\n",
    "        # x = x.cuda()\n",
    "        # y = y.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(x)\n",
    "        y_pred = y_pred.reshape(y.shape[0], y.shape[1])\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "        iou_score = iou_metric(torch.round(y_pred), y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_iou += iou_score.item()\n",
    "        epoch_sum += (torch.sum(y_pred).item() / y_pred.shape[0])\n",
    "        if save_batch:\n",
    "          texample['prediction'] = torch.round(y_pred)\n",
    "          texample['y'] = y\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_iou / len(iterator), epoch_sum / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "182b2c0c-bae7-435c-922a-87a688891f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, iterator, criterion, save_batch=False):\n",
    "    epoch_loss = 0\n",
    "    epoch_iou = 0\n",
    "    epoch_sum = 0\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "       for (x, y) in iterator:\n",
    "          # x = x.cuda()\n",
    "          # y = y.cuda()\n",
    "          \n",
    "          y_pred = model(x)\n",
    "          y_pred = y_pred.reshape(y.shape[0], y.shape[1])\n",
    "\n",
    "          loss = criterion(y_pred, y)\n",
    "          iou_score = iou_metric(torch.round(y_pred), y)\n",
    "\n",
    "          epoch_loss += loss.item()\n",
    "          epoch_iou += iou_score.item()\n",
    "          epoch_sum += (torch.sum(y_pred).item() / y_pred.shape[0])\n",
    "          if save_batch:\n",
    "            vexample['prediction'] = torch.round(y_pred)\n",
    "            vexample['y'] = y\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_iou / len(iterator), epoch_sum / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180f8126-e0ff-4351-aa39-4f4d75e4f104",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "best_validation_loss = float(\"inf\")\n",
    "optimizer = optim.Adam(detector.parameters(), lr = 1e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    save_batch = epoch+1 == EPOCHS\n",
    "    t_loss, t_iou, t_sum = train(detector, train_dl, optimizer, criterion, save_batch=save_batch)\n",
    "    v_loss, v_iou, v_sum = validate(detector, valid_dl, criterion, save_batch=save_batch)\n",
    "\n",
    "    print(f'Train(Epoch{epoch+1}): loss = {t_loss} | iou = {t_iou} | sum = {t_sum}')\n",
    "    print(f'Validate(Epoch{epoch+1}): loss = {v_loss} | iou = {v_iou} | sum = {v_sum}')\n",
    "    print(' --- ')\n",
    "\n",
    "    train_loss.append(t_loss)\n",
    "    val_loss.append(v_loss)\n",
    "    train_iou.append(t_iou)\n",
    "    val_iou.append(v_iou)\n",
    "\n",
    "    if epoch > 0 and best_validation_loss > v_loss:\n",
    "        best_validation_loss = v_loss\n",
    "        torch.save(detector, './ltr_detector.pt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
